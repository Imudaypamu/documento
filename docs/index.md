---
# template: home.html
title: Material for MkDocs
---

# Profile

**Mobile:** 9701514053  
**Email:** imudaykiranpamu@gmail.com  

---

## Professional Summary

- Results-oriented Data Engineer with around 1.7 years of experience in Data Warehousing, ETL development, and Cloud-based Data Engineering, specializing in building scalable data solutions on AWS.
- Expertise in designing, developing, and orchestrating complex data pipelines using AWS Glue, EMR (PySpark), Apache Airflow, and AWS Step Functions to ensure efficient and reliable data movement across environments.
- Deep understanding of AWS Cloud ecosystem including S3 (data lake implementation), Athena (interactive querying), CloudWatch (monitoring and alerting), EventBridge (event-driven workflows), EC2, VPC, and IAM for identity and access management.
- Strong knowledge in Data Warehousing and ETL concepts, Dimensional Modeling, and schema design (Star and Snowflake), enabling faster data retrieval and optimized query performance.
- Proficient in ETL data extraction, transformation, and loading from multiple heterogeneous sources like Oracle, IBM DB2, and flat files, leveraging PySpark, Python, and AWS Glue for scalable transformations and automation.
- Skilled in ETL optimization, parallel processing, partitioning, and data validation to improve pipeline performance, fault tolerance, and cost efficiency within AWS environments.
- Experience in implementing data quality frameworks, error handling mechanisms, and logging solutions to ensure data accuracy and reliability.
- Adept in version control and CI/CD using Git, GitHub, and CodePipeline, ensuring continuous integration and smooth deployment of data workflows.
- Strong SQL development skills for data analysis, transformation, and optimization; hands-on experience with Unix/Linux scripting, PuTTY, and WinSCP for data management and server interaction.
- Exposure to data analytics and visualization using Power BI, translating technical data into meaningful business insights for decision-makers.
- Collaborated with cross-functional teams including Data Scientists, Business Analysts, and DevOps engineers to design and implement scalable, secure, and business-aligned data solutions.
- Experienced in monitoring, troubleshooting, and root cause analysis to resolve pipeline issues, reduce latency, and maintain SLAs.
- Knowledgeable in data governance, security best practices, and cost optimization strategies to ensure compliance and efficient use of AWS resources.
- Enthusiastic about automation, modern data architectures, and continuous learning, with a passion for improving data reliability and accelerating analytics capabilities.

---

## Professional Experience

Working as **AWS Data Engineer and PySpark Developer** at **Accenture**  
**May 2024 – Till Now**

---

## Technical Skills

| Category | Skills |
|--------|--------|
| **AWS Services** | AWS Glue, AWS EMR (PySpark), S3, Athena, Step Functions, IAM, EC2, VPC, Lambda, CloudWatch |
| **Programming and Scripting** | Python, PySpark, SQL, PL/SQL, Unix Shell Scripting |
| **Databases / DBMS** | MySQL, IBM DB2, DBeaver |
| **Operating Systems** | Windows, UNIX, Linux |
| **Scheduling Tools** | Apache Airflow, EventBridge |
| **Version Control / DevOps** | Git, GitHub |
| **Utilities** | VS Code, PuTTY, MS Office |
| **Other Skills** | Data Warehousing, ETL Development, Data Lake Architecture, Pipeline Optimization, Debugging and Troubleshooting, SQL Query Tuning |

---

## Educational Qualification

**B.Tech in Computer Science**  
JNTUK University, Andhra Pradesh  
2023

---

## Project Experience

### Project #1

**Project Title:** American Honda Motor Co., Inc.  
**Domain:** Automotives  
**Role:** AWS Data Engineer and PySpark Developer  
**Duration:** May 2024 – Present  

**Environment:**  
AWS Glue, AWS EMR (PySpark), Apache Airflow, Athena, Step Functions, S3, IAM, EC2, VPC, EventBridge, CloudWatch, Python, SQL, IBM DB2, Power BI, Git, GitHub, PuTTY, Windows, UNIX, Linux, Shell Scripting

### Project Description

The project involved the modernization of American Honda Motor Co.’s enterprise data architecture by building a highly scalable and automated AWS data lake. The goal was to centralize data from multiple sources, optimize ETL pipelines, and provide reliable, analytics-ready datasets for business intelligence and reporting.

The solution leveraged AWS Glue, EMR, S3, Athena, Step Functions, EventBridge, and CloudWatch to design a fully automated, secure, and cost-efficient cloud data platform. The project also emphasized dimensional modeling, performance optimization, data governance, and end-to-end workflow automation to support business decision-making.

### Roles and Responsibilities

- Led the design, development, and deployment of enterprise-grade data pipelines on AWS Cloud using AWS Glue, EMR (PySpark), S3, Athena, Step Functions, and EventBridge.
- Engineered end-to-end ETL processes from IBM DB2, Oracle, and flat file sources into an S3-based data lake architecture using PySpark.
- Implemented dimensional modeling using Star and Snowflake schemas to optimize query performance and analytics.
- Automated and orchestrated workflows using Apache Airflow and AWS Step Functions with event-driven triggers and fault tolerance.
- Designed secure AWS architectures using IAM, VPC isolation, and EC2/EMR configurations.
- Built monitoring, alerting, and logging frameworks using AWS CloudWatch and custom Python and Shell scripts.
- Optimized ETL and data processing using PySpark techniques such as partitioning, caching, and parallel processing.
- Used AWS Athena for ad-hoc data validation, query optimization, and data exploration.
- Applied version control using Git and GitHub and supported CI/CD pipelines.
- Developed automation scripts using Python and Shell for file transfers and batch scheduling.
- Ensured data governance, quality, security, logging, validation, and backup strategies.
- Collaborated with Data Scientists, Analysts, and DevOps teams to deliver scalable and maintainable data solutions.
- Designed reusable PySpark and Glue ETL frameworks to improve productivity and reduce development time.

---

## Certifications and Trainings

- AWS Data Engineering  
- GCP Data Practitioner  
- GCP Associate Cloud Practitioner  
- AZ-900 Azure Fundamentals  

---

## Personal Details

**Name:** Uday Kiran Pamu  
**Date of Birth:** 06-08-2001  
**Gender:** Male  
**Email:** imudaykiranpamu@gmail.com  
**Phone No:** 9701514053  

---

